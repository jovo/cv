@article{Banerjee2013,
 abstract = {An extremely common bottleneck encountered in statistical learning algorithms is inversion of huge covariance matrices, examples being in evaluating Gaussian likelihoods for a large number of data points. We propose general parallel algorithms for inverting positive definite matrices, which are nearly rank deficient. Such matrix inversions are needed in Gaussian process computations, among other settings, and remain a bottleneck even with the increasing literature on low rank approximations. We propose a general class of algorithms for parallelizing computations to dramatically speed up computation time by orders of magnitude exploiting multicore architectures. We implement our algorithm on a cloud computing platform, providing pseudo and actual code. The algorithm can be easily implemented on any multicore parallel computing resource. Some illustrations are provided to give a flavor for the gains and what becomes possible in freeing up this bottleneck.},
 archiveprefix = {arXiv},
 arxivid = {1312.1869},
 author = {Banerjee, Anjishnu and Vogelstein, Joshua and Dunson, David},
 author+an = {2=highlight},
 eprint = {1312.1869},
 journal = {arXiv},
 keywords = {big data,gaussian process,mapreduce,matrix inversion,parallel computing,qr decom-},
 title = {{Parallel inversion of huge covariance matrices}},
 url = {http://arxiv.org/abs/1312.1869},
 volume = {1312.1869},
 year = {2013}
}

@article{Hayden2020,
 author = {Helm, Hayden S. and Basu, Amitabh and Athreya, Avanti and Park, Youngser and Vogelstein, Joshua T. and Winding, Michael and Zlatic, Marta and Cardona, Albert and Bourke, Patrick and Larson, Jonathan and White, Chris and Priebe, Carey E.},
 author+an = {1=trainee; 5=highlight},
 archiveprefix = {arXiv},
 arxivid = {2005.10700},
 eprint = {2005.10700},
 title = {Learning to rank via combining representations},
 url = {https://arxiv.org/abs/2005.10700},
 year = {2020}
}

@MISC{Caplis2017-qk,
  title        = "{Glass box vs. black box}",
  booktitle    = "{Pensions \& Investments}",
  author       = "Caplis, Jonathan and Vogelstein, Joshua T",
  month        =  jul,
  year         =  2017,
  howpublished = "\url{https://www.pionline.com/article/20170727/ONLINE/170729878/glass-box-vs-black-box}",
  note         = "Accessed: 2020-1-14"
}


@article{Kazhdan2013,
 abstract = {We propose a new gradient-domain technique for processing registered EM image stacks to remove the inter-image discontinuities while preserving intra-image detail. To this end, we process the image stack by first performing anisotropic diffusion to smooth the data along the slice axis and then solving a screened-Poisson equation within each slice to re-introduce the detail. The final image stack is both continuous across the slice axis (facilitating the tracking of information between slices) and maintains sharp details within each slice (supporting automatic feature detection). To support this editing, we describe the implementation of the first multigrid solver designed for efficient gradient domain processing of large, out-of-core, voxel grids.},
 archiveprefix = {arXiv},
 arxivid = {1310.0041},
 author = {Kazhdan, Michael and Burns, Randal and Kasthuri, Bobby and Lichtman, Jeff and Vogelstein, Jacob and Vogelstein, Joshua},
 author+an = {6=highlight},
 eprint = {1310.0041},
 journal = {arXiv},
 month = {sep},
 title = {{Gradient-Domain Processing for Large EM Image Stacks}},
 url = {http://arxiv.org/abs/1310.0041},
 year = {2013}
}

@article{kiar2018neurostorm,
 abstract = {Neuroscientists are now able to acquire data at staggering rates across spatiotemporal scales. However, our ability to capitalize on existing datasets, tools, and intellectual capacities is hampered by technical challenges. The key barriers to accelerating scientific discovery correspond to the FAIR data principles: findability, global access to data, software interoperability, and reproducibility/re-usability. We conducted a hackathon dedicated to making strides in those steps. This manuscript is a technical report summarizing these achievements, and we hope serves as an example of the effectiveness of focused, deliberate hackathons towards the advancement of our quickly-evolving field.},
 archiveprefix = {arXiv},
 arxivid = {1803.03367},
 author = {Kiar, Gregory and Anderson, Robert J. and Baden, Alex and Badea, Alexandra and Bridgeford, Eric W. and Champion, Andrew and Chandrashekhar, Vikram and Collman, Forrest and Duderstadt, Brandon and Evans, Alan C. and Engert, Florian and Falk, Benjamin and Glatard, Tristan and Roncal, William R. Gray and Kennedy, David N. and Maitin-Shepard, Jeremy and Marren, Ryan A. and Nnaemeka, Onyeka and Perlman, Eric and Seshamani, Sharmishtaas and Trautman, Eric T. and Tward, Daniel J. and Vald√©s-Sosa, Pedro Antonio and Wang, Qing and Miller, Michael I. and Burns, Randal and Vogelstein, Joshua T.},
 author+an = {2=trainee;3=trainee;5=trainee;7=trainee;9=trainee;27=highlight},
 eprint = {1803.03367},
 journal = {arXiv},
 month = {mar},
 title = {{NeuroStorm: Accelerating Brain Science Discovery in the Cloud}},
 url = {http://arxiv.org/abs/1803.03367},
 year = {2018}
}

@article{Priebe2017,
 abstract = {We present semiparametric spectral modeling of the complete larval Drosophila mushroom body connectome. Motivated by a thorough exploratory data analysis of the network via Gaussian mixture modeling (GMM) in the adjacency spectral embedding (ASE) representation space, we introduce the latent structure model (LSM) for network modeling and inference. LSM is a generalization of the stochastic block model (SBM) and a special case of the random dot product graph (RDPG) latent position model, and is amenable to semiparametric GMM in the ASE representation space. The resulting connectome code derived via semiparametric GMM composed with ASE captures latent connectome structure and elucidates biologically relevant neuronal properties.},
 archiveprefix = {arXiv},
 arxivid = {1705.03297},
 author = {Priebe, Carey E. and Park, Youngser and Tang, Minh and Athreya, Avanti and Lyzinski, Vince and Vogelstein, Joshua T. and Qin, Yichen and Cocanougher, Ben and Eichler, Katharina and Zlatic, Marta and Cardona, Albert},
 author+an = {6=highlight},
 eprint = {1705.03297},
 journal = {arXiv},
 title = {{Semiparametric spectral modeling of the Drosophila connectome}},
 url = {http://arxiv.org/abs/1705.03297},
 year = {2017}
}

@article{sinha2014automatic,
 archiveprefix = {arXiv},
 arxivid = {arXiv:1404.4800},
 author = {Sinha, A and Roncal, WG and Kasthuri, N},
 eprint = {arXiv:1404.4800},
 journal = {arXiv},
 title = {{Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes}},
 url = {http://arxiv.org/abs/1404.4800},
 year = {2014}
}

@article{Zheng2016,
 abstract = {R is one of the most popular programming languages for statistics and machine learning, but the R framework is relatively slow and unable to scale to large datasets. The general approach for speeding up an implementation in R is to implement the algorithms in C or FORTRAN and provide an R wrapper. FlashR takes a different approach: it executes R code in parallel and scales the code beyond memory capacity by utilizing solid-state drives (SSDs) automatically. It provides a small number of generalized operations (GenOps) upon which we reimplement a large number of matrix functions in the R base package. As such, FlashR parallelizes and scales existing R code with little/no modification. To reduce data movement between CPU and SSDs, FlashR evaluates matrix operations lazily, fuses operations at runtime, and uses cache-aware, two-level matrix partitioning. We evaluate FlashR on a variety of machine learning and statistics algorithms on inputs of up to four billion data points. FlashR out-of-core tracks closely the performance of FlashR in-memory. The R code for machine learning algorithms executed in FlashR outperforms the in-memory execution of H2O and Spark MLlib by a factor of 2-10 and outperforms Revolution R Open by more than an order of magnitude.},
 archiveprefix = {arXiv},
 arxivid = {1604.06414},
 author = {Zheng, Da and Mhembere, Disa and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
 author+an = {1=trainee;2=trainee;3=highlight},
 eprint = {1604.06414},
 journal = {CoRR, abs/1604.06414},
 title = {{FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs}},
 url = {http://arxiv.org/abs/1604.06414},
 year = {2017}
}

@article{Zheng2016c,
 abstract = {Many eigensolvers such as ARPACK and Anasazi have been developed to compute eigenvalues of a large sparse matrix. These eigensolvers are limited by the capacity of RAM. They run in memory of a single machine for smaller eigenvalue problems and require the distributed memory for larger problems. In contrast, we develop an SSD-based eigensolver framework called FlashEigen, which extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph with hundreds of millions or even billions of vertices in a single machine. FlashEigen performs sparse matrix multiplication in a semi-external memory fashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in memory. We store the entire vector subspace on SSDs and reduce I/O to improve performance through caching the most recent dense matrix. Our result shows that FlashEigen is able to achieve 40{\%}-60{\%} performance of its in-memory implementation and has performance comparable to the Anasazi eigensolvers on a machine with 48 CPU cores. Furthermore, it is capable of scaling to a graph with 3.4 billion vertices and 129 billion edges. It takes about four hours to compute eight eigenvalues of the billion-node graph using 120 GB memory.},
 archiveprefix = {arXiv},
 arxivid = {1602.01421},
 author = {Zheng, Da and Burns, Randal and Vogelstein, Joshua and Priebe, Carey E. and Szalay, Alexander S.},
 author+an = {1=trainee;3=highlight},
 eprint = {1602.01421},
 journal = {arXiv},
 title = {{An SSD-based eigensolver for spectral analysis on billion-node graphs}},
 url = {http://arxiv.org/abs/1602.01421},
 year = {2016}
}

